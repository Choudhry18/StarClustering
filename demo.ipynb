{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StarcNet demo for NGC1566\n",
    "This notebook executes a demo with **already downloaded** `.fits` and `.tabs` files saved to folders `legus/frc_fits_files` and `legus/tab_files` respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "* [Getting started](#Getting-started)\n",
    "* [Create dataset](#Create-dataset)\n",
    "* [Run StarcNet](#Run-StarcNet)\n",
    "    * [Load dataset](#Load-dataset)\n",
    "    * [Classify objects](#Classify-objects)\n",
    "* [Create text file with predictions](#Create-text-file-with-predictions)\n",
    "* [Create galaxy image with predictions](#Create-galaxy-image-with-predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "sys.path.insert(0, './src/utils')\n",
    "sys.path.insert(0, './model')\n",
    "from data_utils import load_db\n",
    "from starcnet import Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that galaxy name and filenames are already in the `.txt` files `targets.txt`, `frc_fits_links.txt`, and `tab_links.txt`. The complete download link should be added if used with online LEGUS catalogs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngc1566\n",
      "\n",
      "https://archive.stsci.edu/hlsps/legus/ngc1566/ngc1566_drc.tar.gz\n",
      "\n",
      "https://archive.stsci.edu/hlsps/legus/ngc1566/cluster_catalogs/deterministic/hlsp_legus_hst_wfc3_ngc1566_multiband_v1_padagb-mwext-avgapcor.tab\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(open('targets.txt', 'r').read())\n",
    "print(open('frc_fits_links.txt', 'r').read())\n",
    "print(open('tab_links.txt', 'r').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset\n",
    "Create a 32x32x5 array per object in the catalog (`.tab` file). Each array is object centered and has the 5 bands of the photometric information form the HST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating dataset...\n",
      "dataset created\n"
     ]
    }
   ],
   "source": [
    "print('creating dataset...')\n",
    "os.system('bash create_dataset.sh')\n",
    "print('dataset created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run StarcNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64 # input batch size for testing (default: 64)\n",
    "data_dir = 'data/' # dataset directory\n",
    "dataset = 'raw_32x32' # dataset file reference\n",
    "checkpoint = 'model/starcnet.pth' # trained model\n",
    "gpu = '' # CUDA visible device (when using a GPU add GPU id (e.g. '0'))\n",
    "cuda = False # enables CUDA training (when using a GPU change to True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test, _, _ = load_db(os.path.join(data_dir,'test_'+dataset+'.dat'))\n",
    "mean = np.load(data_dir+'mean.npy')\n",
    "\n",
    "data_test -= mean[np.newaxis,:,np.newaxis,np.newaxis] # subtract mean\n",
    "\n",
    "data = torch.from_numpy(data_test).float()\n",
    "test = TensorDataset(data) \n",
    "test_loader = DataLoader(test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_loader):\n",
    "    '''\n",
    "    Forward pass through the CNN for one epoch\n",
    "    '''\n",
    "    model.eval()\n",
    "    predictions = np.array([], dtype=np.int64).reshape(0) # placeholder for all predictions\n",
    "    scores = np.array([], dtype=np.float32).reshape(0,4) # placeholder for all scores\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in enumerate(test_loader):\n",
    "            if cuda:\n",
    "                data = Variable(data[0].cuda())\n",
    "            else:\n",
    "                data = Variable(data[0])\n",
    "            output = model(data) # forward pass through the CNN\n",
    "            pred = output.data.max(1)[1] # get the index of the max log-probability\n",
    "            predictions = np.concatenate((predictions, pred.cpu().numpy()))\n",
    "            scores = np.concatenate((scores, output.data.cpu().numpy()),axis=0)\n",
    "    return predictions, scores\n",
    "\n",
    "\n",
    "def load_weights(model):\n",
    "    '''\n",
    "    Load trained model parameters to current model\n",
    "    '''\n",
    "    model_dict = model.state_dict()\n",
    "    if cuda:\n",
    "        pretrained_dict = torch.load(checkpoint)\n",
    "    else:\n",
    "        pretrained_dict = torch.load(checkpoint, map_location=torch.device('cpu'))\n",
    "    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict and v.size() == model_dict[k].size() }\n",
    "    model_dict.update(pretrained_dict)\n",
    "    model.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of classification | time: 27.67s\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "cuda = cuda and torch.cuda.is_available()\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu\n",
    "\n",
    "model = Net() # create model with StarcNet architecture\n",
    "load_weights(model) # load trained model parameters\n",
    "\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "\n",
    "predictions, scores = test(test_loader) # classify all 32x32x5 arrays\n",
    "\n",
    "np.save(os.path.join('output','scores'), scores) # save scores to 'output/scores.npy' file\n",
    "print('End of classification | time: %.2fs'%(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create text file with predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text file with predictions: 'output/predictions.csv'\n"
     ]
    }
   ],
   "source": [
    "with open('data/test_raw_32x32.dat', 'rb') as infile:\n",
    "    dset = pickle.load(infile)\n",
    "data, ids, galaxies, coords = dset['data'], dset['ids'], dset['galaxies'], dset['coordinates']\n",
    "\n",
    "scores = np.load('output/scores.npy')\n",
    "preds = np.argmax(scores,axis=1)\n",
    "\n",
    "with open('output/predictions.csv', 'w') as csvfile:\n",
    "    filewriter = csv.writer(csvfile, delimiter=',',\n",
    "                            quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    filewriter.writerow(['Galaxy', 'Id', 'X', 'Y','Prediction'])\n",
    "    for i in range(len(ids)):\n",
    "        filewriter.writerow([galaxies[i], ids[i], coords[i][0], coords[i][1], preds[i]+1])\n",
    "\n",
    "print(\"Text file with predictions: 'output/predictions.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create galaxy image with predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image with predictions: 'output/predictions.png'\n"
     ]
    }
   ],
   "source": [
    "os.system('python src/run_visualization.py')\n",
    "print(\"Image with predictions: 'output/predictions.png'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "starcluster",
   "language": "python",
   "name": "starcluster"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
